{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A large portion of this code is taken from Aurélien Géron's: Hands-On machine learning with SciKit-Learn, Keras and Tensorflow (2nd edition). I have put comments based on information in the book as well as information I found elsewhere.\n",
    "\n",
    "## Chapter 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data API (tf.data) allows you to ingest and preprocess a large dataset efficiently. It also works seamlessly with tf.keras.\n",
    "\n",
    "Off-the-shelf, it can read from:\n",
    "  - text files\n",
    "  - binary files with fixed-sized records\n",
    "  - binary files using tensorflow's TFRecord format\n",
    "  - SQL databases\n",
    "Many open-source extensions are available to read from all sorts of data sources (look at the TFIO API https://github.com/tensorflow/io and https://www.tensorflow.org/io/api_docs/python/tfio)\n",
    "\n",
    "This notebook covers:\n",
    "  - the Data API\n",
    "  - the TFRecord format\n",
    "  - how to create custom preprocessing layers\n",
    "  - how to use the standard Keras layers\n",
    "  - projects from the TF ecosystem\n",
    "TF Transform (tf.Transform):\n",
    "  - write a single preprocessing function to run in batch mode on your full training set.\n",
    "  - Preprocess the function itself\n",
    "    - to speed it up\n",
    "    - to export it to a TF function\n",
    "    - incorporate it in your trained model (once it is deployed in production, it can\n",
    "      take care of preprocessing new instances on the fly).\n",
    "TF Datasets (TFDS):\n",
    "  - Provides:\n",
    "    - a convenient function to download many common datasets\n",
    "    - convenient dataset objects (tf.data.dataset) to manipulate the datasets\n",
    "      using the Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=950, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)  # creates dataset in RAM\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def print_dataset(dataset, comment=''):\n",
    "    print(comment)\n",
    "    for item in dataset:\n",
    "        print(item)\n",
    "\n",
    "print_dataset(dataset, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In batch() function, drop_remainder=False (default) :\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n",
      "In batch() function, drop_remainder=True :\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Dataset transformation methods return a new dataset,\n",
    "# so you can chain transformations.\n",
    "# All dataset methods do not modify the existing dataset,\n",
    "# so make sure to specify dataset = dataset.method()\n",
    "# instead of dataset.method(), otherwise the updated\n",
    "# values will not be saved to any variable.\n",
    "\n",
    "# repeat(3) does not take 3x the RAM as the original dataset.\n",
    "dataset1 = dataset.repeat(3). \\\n",
    "            batch(7)                       # by default, drop_remainder=False\n",
    "dataset2 = dataset.repeat(3). \\\n",
    "            batch(7, drop_remainder=True)  # by default, drop_remainder=False\n",
    "print_dataset(dataset1, 'In batch() function, drop_remainder=False (default) :')\n",
    "print_dataset(dataset2, 'In batch() function, drop_remainder=True :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)  # creates dataset in RAM\n",
    "                                                 # Items: [0, 1, 2, 3, 4,  5,  6,  7,  8,  9]\n",
    "dataset2 = dataset.map(lambda x: x * 2)          # Items: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "# The map function is usually applied during preprocessing.\n",
    "\n",
    "# The num_parallel_calls argument tells map() function\n",
    "# to run map() in parallel using the given number of threads.\n",
    "# AUTOTUNE sets the number of threads automatically\n",
    "# to the best possible number.\n",
    "dataset2 = dataset.map(lambda x: x * 2, \n",
    "                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "print_dataset(dataset2, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map() function applies a transformation to each item. It's properties:\n",
    "\n",
    "|if function given to map() returns|result.output_classes =|result.types =|result.output_shapes =|\n",
    "|---|---|---|---|\n",
    "|tf.constant(37.0)|tf.Tensor|tf.float32|[]  # scalar|\n",
    "|tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])|(tf.Tensor, tf.Tensor)|(tf.float32, tf.string)|([], [3])|\n",
    "|37.0, [\"Foo\", \"Bar\", \"Baz\"], np.array([1.0, 2.0] dtype=np.float64)|(tf.Tensor, tf.Tensor, tf.Tensor)|(tf.float32, tf.string, tf.float64)|([], [3], [2])|\n",
    "|{\"a\": 37.0, \"b\": [42, 16]}, \"foo\"|({\"a\": tf.Tensor, \"b\": tf.Tensor}, tf.Tensor)|({\"a\": tf.float32, \"b\": tf.int32}, tf.string)|({\"a\": [], \"b\": [2]}, [])|\n",
    "\n",
    "The apply() function applies a transformation to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before unbatch():\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n",
      "After unbatch():\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "After filter():\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "After take(3):\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.repeat(3).batch(7)\n",
    "\n",
    "print_dataset(dataset1, 'Before unbatch():')\n",
    "dataset2 = dataset1.apply(tf.data.experimental.unbatch())\n",
    "print_dataset(dataset2, 'After unbatch():')\n",
    "\n",
    "dataset3 = dataset2.filter(lambda x: x < 5)\n",
    "print_dataset(dataset3, 'After filter():')\n",
    "\n",
    "dataset4 = dataset2.take(3)\n",
    "print_dataset(dataset4, 'After take(3):')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, a sequential layer has a shuffle=True parameter.\n",
    "This causes the layer to shuffle each dataset before each epoch.\n",
    "This ensures the neural network is not tuning itself to\n",
    "the sequence of inputs in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor([2 5 1 7 0 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 4 3 1 5 6 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 7 2 9 0 3 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([2 8 4 6 8 9 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# You can shuffle the dataset using the shuffle() function.\n",
    "# The buffer argument creates a buffer between the client\n",
    "# of the shuffle() function and the source dataset:\n",
    "#   client <- shuffle() <- buffer <- source dataset\n",
    "# shuffle() pre-populates the buffer from the source dataset.\n",
    "# shuffle() returns items randomly from the buffer when asked,\n",
    "# and keeps refreshing those empty spots from the source dataset\n",
    "# until there are no more items in the source dataset.\n",
    "# Make the buffer_size large enough for it to be effective.\n",
    "# \n",
    "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
    "dataset = dataset.shuffle(buffer_size=5, \n",
    "                          seed=42,\n",
    "                          reshuffle_each_iteration=False).batch(7)\n",
    "print_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.Tensor([2 5 1 7 0 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 4 3 1 5 6 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 7 2 9 0 3 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([2 8 4 6 8 9 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 5 1 7 0 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 4 3 1 5 6 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 7 2 9 0 3 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([2 8 4 6 8 9 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = dataset.repeat(2)\n",
    "print_dataset(dataset2)      # repeat() on a shuffled dataset generates a new order\n",
    "                             # at each iteration, unless reshuffle_each_iteration=False\n",
    "                             # in the shuffle() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Linux shuf command shuffles lines in a file.\n",
    "# For OSX,\n",
    "#   brew install coreutils\n",
    "#   gshuf                  # links to shuf\n",
    "# man shuf or man gshuf for usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interleaving from multiple files\n",
    "\n",
    "Let's figure out how to shuffle using the California Housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
